---
layout: post
title: "Weekly notes"
tags: llms timbray planetscale throttling throttlers throttle
---

* [The Gap Through Which We Praise the Machine](https://ferd.ca/the-gap-through-which-we-praise-the-machine.html): Thoughts about the difference between what ai agents are capable of and where they fit vs in practice. How we're having to adapt ourselves to the misunderstanding / shortcomings of this new tool? (And how well that doesn't usually go.) Listed are several new practices we can try to adopt to increase context available to llms but they're often hit or miss. And discusses the pressure from above to get on this ride.
* [AI Angst](https://www.tbray.org/ongoing/When/202x/2025/06/06/My-AI-Angst): More ai thoughts that are balanced. Good uses, bad uses. Hard to ignore smart people saying there's something here. LLMs are going to be used for terrible things and there will be consequences. We should probably think about environmental impact.
* Series: How to think about throttling an application by planetscale (uses db as an example)
  * What requests should be throttled?
  * What metric do you use to kick in throttler? (eg replication lag)
  * How often to check the metric that decides throttling is needed
  * Queuing theory: Replication lag is "the amount of time a change event waits to be transfered to secondaries from primary and then applied"
  * [Source: Anatomy of a Throttler, part 1](https://planetscale.com/blog/anatomy-of-a-throttler-part-1): Intro to series talks about 