---
layout: post
title:  "Week 27: monitorama pug poe"
---

* [Monitorama PDX 2024 - Pugs, Poe's and pipelines; An engineering perspective on big-data streams](https://www.youtube.com/watch?v=aaQOUmhr9mA): Cost of a data pipeline relates to how much data you push through it. If you can reduce the amount of data persisted at the point you ingest, you can save a lot of complexity and cash. (Filtering + aggregating) Point of enrichment says for each data item, get meta info needed to understand what you're looking at and filter ruthlessly to what you need to run the system. Point of aggregation says for each data item, keep a window of similar data and merge new information into it. (eg Minutely latency data vs a raw stream) You can also merge data later in the pipeline but the cost goes way up. (Talked about summary merge table in clickhouse where the PUG is transparent to users of ch)
    * Neat talk. Data pipeline for monitoring data:
        * Collect
        * Ingest
        * Enrich / transform
        * Store
        * Analyze / decide
        * Alert
