---
layout: post
title:  "Week 23: lizfongjones monitorama monitoring observability, operations kate, cloudflare log pipeline"
---

* [Monitorama BAL 2019 - Coalescing systems data without losing fidelity](https://www.youtube.com/watch?v=kPW3FXU52akf): How do you collect just enough data from a system that's emitting lots of it? Adaptive sampling, avoid aggregation because you lose information, figure out how much you need to collect to be representative of broader data set. Collecting and storing everything can be prohibitively expensive.
* [Software Managersâ€™ Guide to Operational Excellence](https://dl.acm.org/doi/pdf/10.1145/3631176): Things to consider as regular operations tasks for a team that owns security, availability, and performance of software that has to keep running. eg:
    * monitoring
    * incident response
    * disaster recovery, backups
    * oncall
    * platform tools (ci, deployer, config management, etc)
    * [pdf](/assets/2024/Software%20Managers%20Guide%20to%20Operational%20Excellence.pdf)
* [An overview of Cloudflare's logging pipeline](https://blog.cloudflare.com/an-overview-of-cloudflares-logging-pipeline): Cloudflare's logging pipeline including at the source: journald, syslog-ng, kafka, elk and clickhouse. This seems simple and scalable which makes me happy. I didn't know the collector end of the log pipeline could rely on systemd.